{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpuConfig = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=1.0),\n",
    "    device_count={'GPU': 1})\n",
    "\n",
    "sess = tf.Session(config=gpuConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\yfujimoto\\AppData\\Local\\Continuum\\Anaconda3\\envs\\yfujimoto\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Flatten, Dense, Concatenate, Reshape, Conv1D, MaxPooling1D, Permute, Dropout, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LambdaCallback, CSVLogger, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "from keras import backend as K\n",
    "import csv\n",
    "from random import choice\n",
    "import pickle\n",
    "import json\n",
    "import zipfile\n",
    "import keras\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from janome.tokenizer import Tokenizer\n",
    "import re\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_jp_model = Word2Vec.load('model/word2vec.gensim.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924207654927 0.646280544106\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_jp_model.wv.similarity(u'宇多田ヒカル', u'浜崎あゆみ'), word2vec_jp_model.wv.similarity(u'宇多田ヒカル', u'ビートルズ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/intent_data_jp_ja.csv', sep=',', names=['text', 'intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4207, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ラジオ日本聞きたい</td>\n",
       "      <td>JORF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ラジオ日本を聞かせて</td>\n",
       "      <td>JORF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ラジオ日本を再生</td>\n",
       "      <td>JORF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text intent\n",
       "0   ラジオ日本聞きたい   JORF\n",
       "1  ラジオ日本を聞かせて   JORF\n",
       "2    ラジオ日本を再生   JORF"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "data['label'] = le.fit_transform(data['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4207, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ラジオ日本聞きたい</td>\n",
       "      <td>JORF</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ラジオ日本を聞かせて</td>\n",
       "      <td>JORF</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ラジオ日本を再生</td>\n",
       "      <td>JORF</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text intent  label\n",
       "0   ラジオ日本聞きたい   JORF      5\n",
       "1  ラジオ日本を聞かせて   JORF      5\n",
       "2    ラジオ日本を再生   JORF      5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['intent'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ラジオ日本聞きたい</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ラジオ日本を聞かせて</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ラジオ日本を再生</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text  label\n",
       "0   ラジオ日本聞きたい      5\n",
       "1  ラジオ日本を聞かせて      5\n",
       "2    ラジオ日本を再生      5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test, = train_test_split(data, \n",
    "                                                   to_categorical(data['label']), \n",
    "                                                   test_size = .2, \n",
    "                                                   random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>ほうそうだいがくを聞きたい</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ラジオにほんを再生して欲しいのですけど</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>松任谷由実の動画を youtube 再生して</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        text  label\n",
       "1053           ほうそうだいがくを聞きたい      3\n",
       "176      ラジオにほんを再生して欲しいのですけど      5\n",
       "4111  松任谷由実の動画を youtube 再生して     17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_val.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>放送大学を再生してください</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>nhk r 2が聞きたいと思います</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>ナックファイブごが聞きたいと思います</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  label\n",
       "913        放送大学を再生してください      3\n",
       "1387   nhk r 2が聞きたいと思います     19\n",
       "667   ナックファイブごが聞きたいと思います      7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j_tokenizer = Tokenizer()\n",
    "\n",
    "def wakati_reading(text):\n",
    "    tokens = j_tokenizer.tokenize(text.replace(\"'\", \"\").lower())\n",
    "    \n",
    "    exclude_pos = [u'助詞',u'助動詞']\n",
    "    \n",
    "    #分かち書き\n",
    "    tokens_w_space = \"\"\n",
    "    for token in tokens:\n",
    "        partOfSpeech = token.part_of_speech.split(',')[0]\n",
    "        \n",
    "        if partOfSpeech not in exclude_pos:\n",
    "            tokens_w_space = tokens_w_space + \" \" + token.surface\n",
    "\n",
    "    tokens_w_space = tokens_w_space.strip()\n",
    "    \n",
    "    #読み方\n",
    "    tokens_reading = \"\"\n",
    "    for token in tokens:\n",
    "        partOfSpeech = token.part_of_speech.split(',')[0]\n",
    " \n",
    "        if partOfSpeech not in exclude_pos:\n",
    "            if token.reading != \"*\":\n",
    "                tokens_reading = tokens_reading + \" \" + token.reading\n",
    "            elif re.match('^[a-z]+$', token.base_form):\n",
    "                alpha_reading = \"\"\n",
    "                alpha_reading = token.base_form.replace(\"a\", \"エー \")\n",
    "                alpha_reading = alpha_reading.replace(\"b\", \"ビー \")\n",
    "                alpha_reading = alpha_reading.replace(\"c\", \"シー \")\n",
    "                alpha_reading = alpha_reading.replace(\"d\", \"ディー \")\n",
    "                alpha_reading = alpha_reading.replace(\"e\", \"イー \")\n",
    "                alpha_reading = alpha_reading.replace(\"f\", \"エフ \")\n",
    "                alpha_reading = alpha_reading.replace(\"g\", \"ジー \")\n",
    "                alpha_reading = alpha_reading.replace(\"h\", \"エイチ \")\n",
    "                alpha_reading = alpha_reading.replace(\"i\", \"アイ \")\n",
    "                alpha_reading = alpha_reading.replace(\"j\", \"ジェー \")\n",
    "                alpha_reading = alpha_reading.replace(\"k\", \"ケー \")\n",
    "                alpha_reading = alpha_reading.replace(\"l\", \"エル \")\n",
    "                alpha_reading = alpha_reading.replace(\"m\", \"エム \")\n",
    "                alpha_reading = alpha_reading.replace(\"n\", \"エヌ \")\n",
    "                alpha_reading = alpha_reading.replace(\"o\", \"オー \")\n",
    "                alpha_reading = alpha_reading.replace(\"p\", \"ピー \")\n",
    "                alpha_reading = alpha_reading.replace(\"q\", \"キュー \")\n",
    "                alpha_reading = alpha_reading.replace(\"r\", \"アール \")\n",
    "                alpha_reading = alpha_reading.replace(\"s\", \"エス \")\n",
    "                alpha_reading = alpha_reading.replace(\"t\", \"ティー \")\n",
    "                alpha_reading = alpha_reading.replace(\"u\", \"ユー \")\n",
    "                alpha_reading = alpha_reading.replace(\"v\", \"ブイ \")\n",
    "                alpha_reading = alpha_reading.replace(\"w\", \"ダブリュー \")\n",
    "                alpha_reading = alpha_reading.replace(\"x\", \"エックス \")\n",
    "                alpha_reading = alpha_reading.replace(\"y\", \"ワイ \")\n",
    "                alpha_reading = alpha_reading.replace(\"z\", \"ゼット \")\n",
    "\n",
    "                tokens_reading = tokens_reading + \" \" + alpha_reading\n",
    "            elif re.match('^[0-9]+$', token.base_form):\n",
    "                numeric_reading = \"\"\n",
    "                numeric_reading = token.base_form.replace(\"0\", \"ゼロ \")\n",
    "                numeric_reading = numeric_reading.replace(\"1\", \"イチ \")\n",
    "                numeric_reading = numeric_reading.replace(\"2\", \"ニ \")\n",
    "                numeric_reading = numeric_reading.replace(\"3\", \"サン \")\n",
    "                numeric_reading = numeric_reading.replace(\"4\", \"ヨン \")\n",
    "                numeric_reading = numeric_reading.replace(\"5\", \"ゴ \")\n",
    "                numeric_reading = numeric_reading.replace(\"6\", \"ロク \")\n",
    "                numeric_reading = numeric_reading.replace(\"7\", \"ナナ \")\n",
    "                numeric_reading = numeric_reading.replace(\"8\", \"ハチ \")\n",
    "                numeric_reading = numeric_reading.replace(\"9\", \"キュー \")\n",
    "\n",
    "                tokens_reading = tokens_reading + \" \" + numeric_reading.strip()\n",
    "\n",
    "    tokens_reading = tokens_reading.strip()\n",
    "    \n",
    "    feature = tokens_w_space + \" \" + tokens_reading\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfujimoto\\AppData\\Local\\Continuum\\Anaconda3\\envs\\yfujimoto\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "x_train_val['feature'] = x_train_val['text'].apply(lambda x: wakati_reading(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>ほうそうだいがくを聞きたい</td>\n",
       "      <td>3</td>\n",
       "      <td>ほう そう だい がく 聞き ホウ ソウ ダイ ガク キキ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ラジオにほんを再生して欲しいのですけど</td>\n",
       "      <td>5</td>\n",
       "      <td>ラジオ ほん 再生 し 欲しい の ラジオ ホン サイセイ シ ホシイ ノ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>松任谷由実の動画を youtube 再生して</td>\n",
       "      <td>17</td>\n",
       "      <td>松任谷 由実 動画   youtube   再生 し マツトウヤ ユミ ドウガ ワイ オー ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627</th>\n",
       "      <td>それじゃあ さようなら</td>\n",
       "      <td>12</td>\n",
       "      <td>それ   さようなら ソレ サヨウナラ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>fm nhkを再生して欲しいんですけど</td>\n",
       "      <td>20</td>\n",
       "      <td>fm   nhk 再生 し 欲しい ん エフ エム  エヌ エイチ ケー  サイセイ シ ホ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        text  label  \\\n",
       "1053           ほうそうだいがくを聞きたい      3   \n",
       "176      ラジオにほんを再生して欲しいのですけど      5   \n",
       "4111  松任谷由実の動画を youtube 再生して     17   \n",
       "3627             それじゃあ さようなら     12   \n",
       "1662     fm nhkを再生して欲しいんですけど     20   \n",
       "\n",
       "                                                feature  \n",
       "1053                      ほう そう だい がく 聞き ホウ ソウ ダイ ガク キキ  \n",
       "176               ラジオ ほん 再生 し 欲しい の ラジオ ホン サイセイ シ ホシイ ノ  \n",
       "4111  松任谷 由実 動画   youtube   再生 し マツトウヤ ユミ ドウガ ワイ オー ...  \n",
       "3627                                それ   さようなら ソレ サヨウナラ  \n",
       "1662  fm   nhk 再生 し 欲しい ん エフ エム  エヌ エイチ ケー  サイセイ シ ホ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 425 unique words.\n"
     ]
    }
   ],
   "source": [
    "feature = x_train_val[['feature']].values.flatten()\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 2000 # Maximum number of words in a unique BI claims doc\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(feature)\n",
    "word_sequences = tokenizer.texts_to_sequences(feature)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {num} unique words.'.format(num=len(word_index)))\n",
    "\n",
    "padded_word_inputs = pad_sequences(word_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>33</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   1990  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     73   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...      7   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...    116   \n",
       "\n",
       "   1991  1992  1993  1994  1995  1996  1997  1998  1999  \n",
       "0    75   121   122     1    74    76    33   123     2  \n",
       "1     3    20    11     6    78     8     4    21    12  \n",
       "2    43    48    64    23    64    26    29     8     4  \n",
       "\n",
       "[3 rows x 2000 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train_pd = pd.DataFrame(padded_word_inputs)\n",
    "padded_train_pd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val, = train_test_split(padded_train_pd, \n",
    "                                                   to_categorical(x_train_val['label']), \n",
    "                                                   test_size = .2, \n",
    "                                                   random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...   1990  \\\n",
       "2394     0     0     0     0     0     0     0     0     0     0  ...     18   \n",
       "2944     0     0     0     0     0     0     0     0     0     0  ...      3   \n",
       "1387     0     0     0     0     0     0     0     0     0     0  ...     11   \n",
       "\n",
       "      1991  1992  1993  1994  1995  1996  1997  1998  1999  \n",
       "2394    46     1    14     5    17    13    34     2    15  \n",
       "2944    20     6    31    22     5    34     8     4    21  \n",
       "1387     6    31    22     5    34     8     4    21    12  \n",
       "\n",
       "[3 rows x 2000 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2692, 2000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673, 2000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_layer = word2vec_jp_model.wv.get_keras_embedding(train_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfujimoto\\AppData\\Local\\Continuum\\Anaconda3\\envs\\yfujimoto\\lib\\site-packages\\ipykernel\\__main__.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=128, activation=\"relu\", kernel_size=3)`\n",
      "C:\\Users\\yfujimoto\\AppData\\Local\\Continuum\\Anaconda3\\envs\\yfujimoto\\lib\\site-packages\\ipykernel\\__main__.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=128, activation=\"relu\", kernel_size=4)`\n",
      "C:\\Users\\yfujimoto\\AppData\\Local\\Continuum\\Anaconda3\\envs\\yfujimoto\\lib\\site-packages\\ipykernel\\__main__.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=128, activation=\"relu\", kernel_size=5)`\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "convs = []\n",
    "filter_sizes = [3,4,5]\n",
    "\n",
    "#Based on https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "for fsz in filter_sizes:\n",
    "    l_conv = Conv1D(nb_filter=128,filter_length=fsz,activation='relu')(embedded_sequences)\n",
    "    l_conv = Dropout(.25)(l_conv)\n",
    "    l_pool = MaxPooling1D(5)(l_conv)\n",
    "    l_pool = Dropout(.25)(l_pool)\n",
    "    convs.append(l_pool)\n",
    "\n",
    "l_merge = Concatenate()(convs)\n",
    "l_merge = Dropout(.25)(l_merge)\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(l_merge)\n",
    "l_cov1 = Dropout(.25)(l_cov1)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_pool1 = Dropout(.25)(l_pool1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_cov2 = Dropout(.25)(l_cov2)\n",
    "l_pool2 = MaxPooling1D(30)(l_cov2)\n",
    "l_pool2 = Dropout(.25)(l_pool2)\n",
    "l_flat = Flatten()(l_pool2)\n",
    "l_flat = Dropout(.25)(l_flat)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "l_dense = Dropout(.25)(l_dense)\n",
    "preds = Dense(21, activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, outputs=preds)\n",
    "opt = SGD(lr = 0.01, momentum = 0.9)\n",
    "\n",
    "model.compile(optimizer = opt, loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = './model/model_v1.{epoch:02d}-{val_loss:.2f}.hdf5', verbose = 1, save_best_only = True)\n",
    "csv_logger = CSVLogger('./model/model_v1.log')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2,\n",
    "                  patience = 5, min_lr = 0.001)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(data['label']), data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=x_train.values, y=y_train, validation_data=(x_val.values, y_val),\n",
    "          epochs=30, batch_size=batch_size, verbose = 0,\n",
    "          callbacks = [reduce_lr, csv_logger, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='acc')\n",
    "plt.plot(epochs, val_acc, label='val_acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, label='loss')\n",
    "plt.plot(epochs, val_loss, label='val_loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, protocol=2)\n",
    "\n",
    "save_object(tokenizer, './model/word_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "model = load_model(filepath='./model/model_v1.26-0.19.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_obj(filename):\n",
    "    with open(filename, 'rb') as handler:\n",
    "        return pickle.load(handler)\n",
    "\n",
    "tokenizer = load_obj('./model/word_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test['feature'] = x_test['text'].apply(lambda x: wakati_reading(x))\n",
    "\n",
    "feature = x_test[['feature']].values.flatten()\n",
    "MAX_SEQUENCE_LENGTH = 2000\n",
    "test_word_sequences = tokenizer.texts_to_sequences(feature)\n",
    "padded_test_word_inputs = pad_sequences(test_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "x_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(padded_test_word_inputs)\n",
    "test_pred_pd = pd.DataFrame(test_predictions)\n",
    "x_test = x_test.reset_index(drop=True)\n",
    "\n",
    "test_result_pd = pd.concat([x_test, test_pred_pd], axis=1)\n",
    "test_result_pd.columns = ['text', 'label', 'feature', 'prob_1', 'prob_2', 'prob_2', 'prob_3', 'prob_4', 'prob_5', 'prob_6', 'prob_7', 'prob_8', 'prob_9', 'prob_10', 'prob_11', 'prob_12', 'prob_13', 'prob_14', 'prob_15', 'prob_16', 'prob_17', 'prob_18', 'prob_19', 'prob_20']\n",
    "test_result_pd.head(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
