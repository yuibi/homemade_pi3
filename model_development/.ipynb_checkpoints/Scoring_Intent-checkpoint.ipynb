{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from janome.tokenizer import Tokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOLUMEUP\n"
     ]
    }
   ],
   "source": [
    "j_tokenizer = Tokenizer()\n",
    "\n",
    "def wakati_reading(text):\n",
    "    tokens = j_tokenizer.tokenize(text.replace(\"'\", \"\").lower())\n",
    "    \n",
    "    exclude_pos = [u'助動詞']\n",
    "    \n",
    "    #分かち書き\n",
    "    tokens_w_space = \"\"\n",
    "    for token in tokens:\n",
    "        partOfSpeech = token.part_of_speech.split(',')[0]\n",
    "        \n",
    "        if partOfSpeech not in exclude_pos:\n",
    "            tokens_w_space = tokens_w_space + \" \" + token.surface\n",
    "\n",
    "    tokens_w_space = tokens_w_space.strip()\n",
    "    \n",
    "    #読み方\n",
    "    tokens_reading = \"\"\n",
    "    for token in tokens:\n",
    "        partOfSpeech = token.part_of_speech.split(',')[0]\n",
    " \n",
    "        if partOfSpeech not in exclude_pos:\n",
    "            if token.reading != \"*\":\n",
    "                tokens_reading = tokens_reading + \" \" + token.reading\n",
    "            elif re.match('^[a-z]+$', token.base_form):\n",
    "                alpha_reading = \"\"\n",
    "                alpha_reading = token.base_form.replace(\"a\", \"エー \")\n",
    "                alpha_reading = alpha_reading.replace(\"b\", \"ビー \")\n",
    "                alpha_reading = alpha_reading.replace(\"c\", \"シー \")\n",
    "                alpha_reading = alpha_reading.replace(\"d\", \"ディー \")\n",
    "                alpha_reading = alpha_reading.replace(\"e\", \"イー \")\n",
    "                alpha_reading = alpha_reading.replace(\"f\", \"エフ \")\n",
    "                alpha_reading = alpha_reading.replace(\"g\", \"ジー \")\n",
    "                alpha_reading = alpha_reading.replace(\"h\", \"エイチ \")\n",
    "                alpha_reading = alpha_reading.replace(\"i\", \"アイ \")\n",
    "                alpha_reading = alpha_reading.replace(\"j\", \"ジェー \")\n",
    "                alpha_reading = alpha_reading.replace(\"k\", \"ケー \")\n",
    "                alpha_reading = alpha_reading.replace(\"l\", \"エル \")\n",
    "                alpha_reading = alpha_reading.replace(\"m\", \"エム \")\n",
    "                alpha_reading = alpha_reading.replace(\"n\", \"エヌ \")\n",
    "                alpha_reading = alpha_reading.replace(\"o\", \"オー \")\n",
    "                alpha_reading = alpha_reading.replace(\"p\", \"ピー \")\n",
    "                alpha_reading = alpha_reading.replace(\"q\", \"キュー \")\n",
    "                alpha_reading = alpha_reading.replace(\"r\", \"アール \")\n",
    "                alpha_reading = alpha_reading.replace(\"s\", \"エス \")\n",
    "                alpha_reading = alpha_reading.replace(\"t\", \"ティー \")\n",
    "                alpha_reading = alpha_reading.replace(\"u\", \"ユー \")\n",
    "                alpha_reading = alpha_reading.replace(\"v\", \"ブイ \")\n",
    "                alpha_reading = alpha_reading.replace(\"w\", \"ダブリュー \")\n",
    "                alpha_reading = alpha_reading.replace(\"x\", \"エックス \")\n",
    "                alpha_reading = alpha_reading.replace(\"y\", \"ワイ \")\n",
    "                alpha_reading = alpha_reading.replace(\"z\", \"ゼット \")\n",
    "\n",
    "                tokens_reading = tokens_reading + \" \" + alpha_reading\n",
    "            elif re.match('^[0-9]+$', token.base_form):\n",
    "                numeric_reading = \"\"\n",
    "                numeric_reading = token.base_form.replace(\"0\", \"ゼロ \")\n",
    "                numeric_reading = numeric_reading.replace(\"1\", \"イチ \")\n",
    "                numeric_reading = numeric_reading.replace(\"2\", \"ニ \")\n",
    "                numeric_reading = numeric_reading.replace(\"3\", \"サン \")\n",
    "                numeric_reading = numeric_reading.replace(\"4\", \"ヨン \")\n",
    "                numeric_reading = numeric_reading.replace(\"5\", \"ゴ \")\n",
    "                numeric_reading = numeric_reading.replace(\"6\", \"ロク \")\n",
    "                numeric_reading = numeric_reading.replace(\"7\", \"ナナ \")\n",
    "                numeric_reading = numeric_reading.replace(\"8\", \"ハチ \")\n",
    "                numeric_reading = numeric_reading.replace(\"9\", \"キュー \")\n",
    "\n",
    "                tokens_reading = tokens_reading + \" \" + numeric_reading.strip()\n",
    "\n",
    "    tokens_reading = tokens_reading.strip()\n",
    "    \n",
    "    feature = tokens_w_space + \" \" + tokens_reading\n",
    "    \n",
    "    return feature\n",
    "\n",
    "def predict_intent(clean_text):\n",
    "    data = np.array([clean_text])\n",
    "    model = joblib.load('./model/ja_jp_v5.pkl')\n",
    "    prediction = model.predict(data)\n",
    "    intent_list = ['BAYFM78', 'FMJ', 'FMT', 'HOUSOU-DAIGAKU', 'INT', 'JORF', 'LFR', 'NACK5', 'NEXT', 'QRR', 'RN1', 'RN2', 'STOP', 'TBS', 'VOLUMEDOWN', 'VOLUMEUP', 'YFM', 'YOUTUBE', 'radiru_r1', 'radiru_r2', 'radiru_r3']\n",
    "    \n",
    "    intent = intent_list[int(prediction)]\n",
    "    \n",
    "    return intent\n",
    "\n",
    "raw_text = \"もうちょっとさ音を大きくしてよ\"\n",
    "clean_text = wakati_reading(raw_text)\n",
    "intent = predict_intent(clean_text)\n",
    "print(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0, 7, 16, 3, 18, 19, 20, 13, 9, 6, 10, 11, 4, 2, 1, 12, 15, 14, 8, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5,  0,  7, 16,  3, 18, 19, 20, 13,  9,  6, 10, 11,  4,  2,  1, 12, 15, 14,  8, 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "あのラジオ日本が聞きたいんですが,JORF\n",
    "bay sm をかけてください,BAYFM78\n",
    "fm nack 5 に変えて,NACK5\n",
    "横浜 fm にしてね,YFM\n",
    "放送大学がいいと思う,HOUSOU-DAIGAKU\n",
    "nhk ラジオ第一に回して,radiru_r1\n",
    "nhk ラジオ r 2 がいいので聞かせて,radiru_r2\n",
    "nhk fm ラジオ聞かせて,radiru_r3\n",
    "tbs ラジオを再生して,TBS\n",
    "文化放送を再生して　お願い,QRR\n",
    "日本放送をかけて,LFR\n",
    "日経第一放送を再生,RN1\n",
    "日経第二をつけてください,RN2\n",
    "inter fm 8 9 がいいな,INT\n",
    "東京 fm のラジオが聞きたい,FMT\n",
    "j wave に変更お願いします,FMJ\n",
    "さよなら,STOP\n",
    "もうちょっとさ音を大きくしてよ,VOLUMEUP\n",
    "あとすこし音量下げて,VOLUMEDOWN\n",
    "次の歌お願い,NEXT\n",
    "東京事変の遭難を再生して,YOUTUBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(を)?再生(.*?)$\n",
    "(を|が)?聞(か|き|く|け|こ)(.*?)$\n",
    "(の)?動画(.*?)$\n",
    "(で|を)見(.*?)$\n",
    "youtube\n",
    "を(\\s*?)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
